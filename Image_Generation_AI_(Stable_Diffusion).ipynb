{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpjNvUA2YG0Rxl8n0BMfGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/Using-Stable-Diffusion-in-Google-Colab/blob/main/Image_Generation_AI_(Stable_Diffusion).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=fbb03b>事前準備\n",
        "- ライブラリのインストール\n",
        "- ライブラリインポート\n",
        "- Hugging Faceにログイン"
      ],
      "metadata": {
        "id": "uvexwfkWvyIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output"
      ],
      "metadata": {
        "id": "Zf9LI83X12LC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "Qr9-paw_rk3k"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをインストール\n",
        "!pip install diffusers transformers peft\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: diffusers, transformers, peft の3つのライブラリをインストールします。これにより、DiffusionPipeline（拡散モデル）や他の機械学習モデルを使用できるようになります。\n",
        "\n",
        "- diffusers: 拡散モデルを実装したライブラリ。\n",
        "- transformers: トランスフォーマーモデル（BERTやGPTなど）を扱うためのライブラリ。\n",
        "- peft: パラメータ効率の良いファインチューニング（PEFT）を行うためのライブラリ。"
      ],
      "metadata": {
        "id": "FNVz3vxGvKGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインポート\n",
        "import torch  # PyTorchのライブラリをインポート\n",
        "\n",
        "# 必要に応じてDiffusionPipelineまたはStableDiffusionPipelineをインポート\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "import matplotlib.pyplot as plt # 可視化のためのライブラリをインポート"
      ],
      "metadata": {
        "id": "hCCpuCfRrtU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: torchはPyTorchのコアライブラリをインポートし、DiffusionPipelineは拡散モデルを簡単に利用できるようにするためのクラスを提供しています。\n",
        "\n",
        "**torch**: ディープラーニングのフレームワーク。\n",
        "\n",
        "**DiffusionPipeline**: テキストや画像生成のための拡散モデルパイプラインを提供するクラス。\n",
        "\n",
        "- 説明: DiffusionPipelineは、一般的な拡散モデルを扱うためのベースクラスです。このクラスは、さまざまな拡散モデル（Stable Diffusionを含む）に対して使用できますが、特定のモデル向けの最適化はされていない場合があります。\n",
        "- 主な機能:\n",
        "  - さまざまな拡散モデルを利用するための汎用的な機能を提供します。\n",
        "  - モデルを選択する柔軟性があるため、異なる拡散技術を使いたい場合に便利です。\n",
        "\n",
        "**StableDiffusionPipeline**: 高品質な画像生成のためのパイプラインを提供するクラス。テキストプロンプトを基にリアルな画像を生成する機能を持つ。\n",
        "- 説明: StableDiffusionPipelineは、Stable Diffusionモデル専用のパイプラインクラスです。これを使用すると、Stable Diffusionに特化した設定やオプションを簡単に利用できます。\n",
        "- 主な機能:\n",
        "  - 特定のプロンプトに基づいて画像を生成します。\n",
        "  - モデルの設定がStable Diffusion向けに最適化されているため、使いやすさが向上します。"
      ],
      "metadata": {
        "id": "gfQwhHhPwBka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFaceアカウントと紐付ける\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login() # Hugging Faceにログイン（Access TokensのValueを入力）\n",
        "\n",
        "# # terminal等の他環境の場合はhuggingface-cli loginを実行(*にアクセストークンをコピペする)\n",
        "# !huggingface-cli login --token ***************"
      ],
      "metadata": {
        "id": "ngGZlzSDc7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=fbb03b>使用するモデルについて\n",
        "- 使用するモデルの指定\n",
        "- モデルを学習済みのものから読み込み"
      ],
      "metadata": {
        "id": "CecFddHowWYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.DiffusionPipelineを使用する場合"
      ],
      "metadata": {
        "id": "oYcvHMTgS6XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'gsdf/Counterfeit-V2.5'  # 使用するモデルIDを指定\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")  # モデルを事前学習済みのものから読み込む"
      ],
      "metadata": {
        "id": "ITerjVgLz7Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hugging Faceモデルハブで公開されているモデルのIDを指定します。ここでは例として'gsdf/Counterfeit-V2.5'という名前のモデルを使用しています。\n",
        " - モデルID: Hugging Faceで管理されている拡散モデルの識別子。\n",
        "\n",
        "- from_pretrainedメソッドを使って、指定したmodel_idの事前学習済みモデルをHugging Faceのリポジトリから読み込みます。\n",
        " - from_pretrained: 指定したモデルを事前に学習した状態でロードする関数。"
      ],
      "metadata": {
        "id": "T1d76cbXwmod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.StableDiffusionPipelineを使用する場合"
      ],
      "metadata": {
        "id": "kHe6bTpXTNLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stable Diffusionを使用して高品質なリアルな画像を生成するための一般的なモデル\n",
        "model_id = \"stabilityai/stable-diffusion-2\" # 使用するモデルを入力\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True, torch_dtype=torch.float16).to(\"cuda\")"
      ],
      "metadata": {
        "id": "h_zX0VU-yn-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StableDiffusionPipeline使用の補足説明\n",
        "以下の3パターンのコードは、`StableDiffusionPipeline` を初期化する方法ですが、それぞれ異なるオプションが指定されています。これらの違いを説明します。\n",
        "\n",
        "### 1. `pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")`\n",
        "- **torch_dtype=torch.float16**: このオプションは、モデルの重みを16ビット浮動小数点（`float16`）形式で読み込むことを指定します。これにより、メモリ使用量を削減し、GPU上での計算を高速化することが可能です。\n",
        "- **.to(\"cuda\")**: モデルをGPUに転送するためのメソッドです。これにより、GPUを利用してより高速な計算を行うことができます。特に、画像生成タスクでは処理速度が向上します。\n",
        "\n",
        "### 2. `pipe = StableDiffusionPipeline.from_pretrained(model_id)`\n",
        "- **デフォルト設定**: こちらのコードは、特にオプションを指定せずにモデルを読み込む方法です。デフォルトでは、モデルは32ビット浮動小数点（`float32`）形式でロードされ、CPUまたはGPUに明示的に転送されることはありません。\n",
        "- **GPUに自動転送されない**: 明示的に`.to(\"cuda\")`を指定しない限り、モデルはCPU上で実行されます。\n",
        "\n",
        "### 3. `pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True)`\n",
        "- **use_auth_token=True**: このオプションは、Hugging Face Hubに対する認証トークンを使用して、プライベートモデルやアクセス制限のあるモデルを取得することを指定します。このトークンが必要な場合に、正しい認証が行われるようにします。\n",
        "- **その他の設定はデフォルト**: モデルはデフォルトの32ビット浮動小数点形式で読み込まれ、CPU上で実行されます（GPUに移動する場合は `.to(\"cuda\")` が必要）。\n",
        "\n",
        "### まとめ\n",
        "- **メモリと速度**: `torch_dtype=torch.float16` は、メモリ効率と速度向上を図るためのオプションです。\n",
        "- **GPUの使用**: `.to(\"cuda\")` を使用すると、計算速度が向上しますが、デフォルトの設定ではCPUで実行されます。\n",
        "- **認証**: `use_auth_token=True` を指定することで、プライベートモデルへのアクセスが可能になります。\n",
        "\n",
        "これにより、各パターンは異なる使用目的や実行環境に応じて最適化されています。"
      ],
      "metadata": {
        "id": "HAari6m8bI7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=fbb03b>画像の生成\n",
        "- 入力するプロンプトを定義\n",
        "- 生成した画像の取得"
      ],
      "metadata": {
        "id": "A1EZAnng2mng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ポジティブプロンプトとネガティブプロンプトのトークン埋め込みを自動的に連結し、Token長が制限を超える場合でも埋め込みを生成できるようにする関数\n",
        "def token_auto_concat_embeds(pipe, positive, negative):\n",
        "    max_length = pipe.tokenizer.model_max_length\n",
        "    positive_length = pipe.tokenizer(positive, return_tensors=\"pt\").input_ids.shape[-1]\n",
        "    negative_length = pipe.tokenizer(negative, return_tensors=\"pt\").input_ids.shape[-1]\n",
        "\n",
        "    print(f'Token length is model maximum: {max_length}, positive length: {positive_length}, negative length: {negative_length}.')\n",
        "    if max_length < positive_length or max_length < negative_length:\n",
        "        print('Concatenated embedding.')\n",
        "        if positive_length > negative_length:\n",
        "            positive_ids = pipe.tokenizer(positive, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "            negative_ids = pipe.tokenizer(negative, truncation=False, padding=\"max_length\", max_length=positive_ids.shape[-1], return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "        else:\n",
        "            negative_ids = pipe.tokenizer(negative, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "            positive_ids = pipe.tokenizer(positive, truncation=False, padding=\"max_length\", max_length=negative_ids.shape[-1],  return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "    else:\n",
        "        positive_ids = pipe.tokenizer(positive, truncation=False, padding=\"max_length\", max_length=max_length,  return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "        negative_ids = pipe.tokenizer(negative, truncation=False, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "    positive_concat_embeds = []\n",
        "    negative_concat_embeds = []\n",
        "    for i in range(0, positive_ids.shape[-1], max_length):\n",
        "        positive_concat_embeds.append(pipe.text_encoder(positive_ids[:, i: i + max_length])[0])\n",
        "        negative_concat_embeds.append(pipe.text_encoder(negative_ids[:, i: i + max_length])[0])\n",
        "\n",
        "    positive_prompt_embeds = torch.cat(positive_concat_embeds, dim=1)\n",
        "    negative_prompt_embeds = torch.cat(negative_concat_embeds, dim=1)\n",
        "    return positive_prompt_embeds, negative_prompt_embeds"
      ],
      "metadata": {
        "id": "krXwNtjXvKFU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# プロンプトとネガティブプロンプトを定義\n",
        "POSITIVE_PROMPT = \"プロンプトを入力\"\n",
        "\n",
        "NEGATIVE_PROMPT = \"ネガティブプロンプトを入力\"\n",
        "\n",
        "# Toekn concatenated embedding\n",
        "positive_embeds, negative_embeds = token_auto_concat_embeds(pipe, POSITIVE_PROMPT, NEGATIVE_PROMPT)"
      ],
      "metadata": {
        "id": "Pk30fxxWs5El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: 生成したい画像を説明するテキスト（プロンプト）を入力します。このプロンプトに基づいて拡散モデルが画像を生成します。\n",
        "- プロンプト: モデルが生成するための指示（テキスト）。"
      ],
      "metadata": {
        "id": "ruj2hUIZxTs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 一枚の画像を生成する方法"
      ],
      "metadata": {
        "id": "n5YAFcVnK4zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "OL5Fn-bISHf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # NSFWフィルターを無効化（自己責任）\n",
        "# pipe.safety_checker = None\n",
        "\n",
        "# 一枚の画像を生成\n",
        "img = pipe(prompt_embeds=positive_embeds,\n",
        "           negative_prompt_embeds=negative_embeds,\n",
        "           height=768, width=512, guidance_scale=12,\n",
        "           torch_dtype=torch.float16).images[0] # プロンプトを使って画像を生成し、その画像を取得"
      ],
      "metadata": {
        "id": "NYYcC4oHtXtE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を取得して表示\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # 軸を非表示にする\n",
        "plt.show()  # 画像をColab上で表示"
      ],
      "metadata": {
        "id": "UdcSetT0grX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: pipeにプロンプトを渡して画像生成を行います。上記の例では生成された1枚の画像を取得しています。\n",
        "- pipe(prompt): プロンプトに基づいて拡散モデルが画像を生成。\n",
        "- .images[0]: 生成された画像リストの中から画像を取り出す。"
      ],
      "metadata": {
        "id": "_BxtD64uyLG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 生成枚数を指定して複数の画像を生成する方法"
      ],
      "metadata": {
        "id": "jcYP06J4LBGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1j2ovSCZKFlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # NSFWフィルターを無効化（自己責任）\n",
        "# pipe.safety_checker = None\n",
        "\n",
        "# 画像の枚数を指定\n",
        "num_images = 4 # 生成する画像の数を指定\n",
        "images = pipe(prompt_embeds=positive_embeds,\n",
        "              negative_prompt_embeds=negative_embeds,\n",
        "              height=768, width=512, guidance_scale=12,\n",
        "              num_images_per_prompt=num_images,\n",
        "              torch_dtype=torch.float16).images[:] # プロンプトを使って画像を生成し、取得する画像を指定"
      ],
      "metadata": {
        "id": "brVwgFDj78JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を取得して表示\n",
        "for i, img in enumerate(images[:]):\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # 軸を非表示にする\n",
        "    plt.show()  # 画像をColab上で表示"
      ],
      "metadata": {
        "id": "PbbJfy32gWUC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: pipeにプロンプトを渡して画像生成を行います。生成された複数の画像のうち、指定された画像を取得しています。\n",
        "- pipe(prompt, num_images_per_prompt=num_images): プロンプトに基づいて拡散モデルが画像を生成。\n",
        "  - num_images_per_promptを使って、必要な画像の枚数を指定します。たとえば、num_images_per_prompt = 10と設定すると、10枚の画像が生成されます。\n",
        "- .images[:5]: 生成された画像リストの中から1から5枚目（listの0~4番目）の画像を取り出す。\n",
        "  - Pythonのリストでは、list[start:end]の形式でスライスが可能です。この場合、最初の5枚を取得するにはimages[:5]と書きます。"
      ],
      "metadata": {
        "id": "44Rqm44RMhCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=fbb03b>生成した画像の保存"
      ],
      "metadata": {
        "id": "0TrJtqOm2dk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルを実行してドライブをマウントし実行ディレクトリへ移動します."
      ],
      "metadata": {
        "id": "nWHHq2Ao2jER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive をマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 以下はサンプルです.ご自身の環境に合わせてフォルダへのパスは変更してください.\n",
        "%cd /content/drive/My Drive/Colab Notebooks/【画像生成】Stable Dffusion"
      ],
      "metadata": {
        "id": "5y33XP_A2Xh-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 一枚の画像を生成する方法で取得した画像の保存"
      ],
      "metadata": {
        "id": "cHz-Snc79evY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# img.save(\"ファイル名.jpg\") # 生成された画像を指定したファイル名で保存\n",
        "img.save(\"/content/drive/MyDrive//Colab Notebooks/【画像生成】Stable Dffusion/ファイル名.jpg\") # ファイル名を入力してその画像ファイルをGoogle Driveに保存"
      ],
      "metadata": {
        "id": "bSFSpcwJtfH3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**: 生成した画像を「ファイル名（ここにファイル名を入力する）.jpg」として保存します。ここで指定したファイル名で保存先が決まります。\n",
        "- img.save: 画像を指定された名前のファイルとして保存するメソッド。"
      ],
      "metadata": {
        "id": "vgwABf5vyfQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像の枚数を指定する方法で取得した画像の保存"
      ],
      "metadata": {
        "id": "rAVmfB-79mli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1～4枚目(listの0,1,2,3)の画像を取得\n",
        "my_images = images[:4]\n",
        "\n",
        "# それぞれの画像を保存\n",
        "for i, img in enumerate(my_images):\n",
        "    img.save(f\"/content/drive/MyDrive//Colab Notebooks/【画像生成】Stable Dffusion/image_{i+1}.jpg\")  # \"image_1.jpg\", \"image_2.jpg\", \"image_3.jpg\", \"image_4.jpg\" というファイル名で保存"
      ],
      "metadata": {
        "id": "Zk4_S0LI9KS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解説**:\n",
        "\n",
        "このコードでは、生成された画像を my_images にスライスで格納しています。それぞれの画像は image_1.jpg、image_2.jpg、image_3.jpg、image4.jpg という名前で保存されます。"
      ],
      "metadata": {
        "id": "phHWvepyJzqr"
      }
    }
  ]
}